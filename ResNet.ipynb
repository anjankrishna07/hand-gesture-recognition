{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import os\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "from torchvision.datasets import ImageFolder\n",
    "from torch.utils.data import DataLoader, ConcatDataset\n",
    "import torch\n",
    "from torchvision import datasets\n",
    "from torchvision.transforms import transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BasicBlock(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, stride=1):\n",
    "        super(BasicBlock, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(in_channels, out_channels, kernel_size=3, stride=stride, padding=1, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(out_channels)\n",
    "        self.conv2 = nn.Conv2d(out_channels, out_channels, kernel_size=3, stride=1, padding=1, bias=False)\n",
    "        self.bn2 = nn.BatchNorm2d(out_channels)\n",
    "        self.shortcut = nn.Sequential()\n",
    "        if stride != 1 or in_channels != out_channels:\n",
    "            self.shortcut = nn.Sequential(\n",
    "                nn.Conv2d(in_channels, out_channels, kernel_size=1, stride=stride, bias=False),\n",
    "                nn.BatchNorm2d(out_channels)\n",
    "            )    \n",
    "    def forward(self, x):\n",
    "        out = F.relu(self.bn1(self.conv1(x)))\n",
    "        out = self.bn2(self.conv2(out))\n",
    "        out += self.shortcut(x)\n",
    "        out = F.relu(out)\n",
    "        return out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResNet18(nn.Module):\n",
    "    def __init__(self, num_classes=10):\n",
    "        super(ResNet18, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 64, kernel_size=3, stride=1, padding=1, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(64)\n",
    "        self.layer1 = nn.Sequential(\n",
    "            BasicBlock(64, 64),\n",
    "            BasicBlock(64, 64)\n",
    "        )\n",
    "        self.layer2 = nn.Sequential(\n",
    "            BasicBlock(64, 128, stride=2),\n",
    "            BasicBlock(128, 128)\n",
    "        )\n",
    "        self.layer3 = nn.Sequential(\n",
    "            BasicBlock(128, 256, stride=2),\n",
    "            BasicBlock(256, 256)\n",
    "        )\n",
    "        self.layer4 = nn.Sequential(\n",
    "            BasicBlock(256, 512, stride=2),\n",
    "            BasicBlock(512, 512)\n",
    "        )\n",
    "        self.avgpool = nn.AdaptiveAvgPool2d((1, 1))\n",
    "        self.fc = nn.Linear(512, num_classes)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        out = F.relu(self.bn1(self.conv1(x)))\n",
    "        out = self.layer1(out)\n",
    "        out = self.layer2(out)\n",
    "        out = self.layer3(out)\n",
    "        out = self.layer4(out)\n",
    "        out = self.avgpool(out)\n",
    "        out = out.view(out.size(0), -1)\n",
    "        out = self.fc(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(epochs,model,train_load,val_load,test_load,loss_func,gradient_descent):\n",
    "    train_loss=[]\n",
    "    training_accuracy=[]\n",
    "    validation_loss=[]\n",
    "    validation_accuracy=[]\n",
    "    testing_accuracy=[]\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model=model.to(device)\n",
    "    for i in range(epochs):\n",
    "        training_loss=0\n",
    "        correct_predicted=0\n",
    "        model.train()\n",
    "        for image,label in train_load:\n",
    "            image,label=image.to(device),label.to(device)\n",
    "            output=model(image)\n",
    "            loss=loss_func(output,label)\n",
    "            gradient_descent.zero_grad()\n",
    "            loss.backward()\n",
    "            gradient_descent.step()\n",
    "            training_loss+=loss.item()*len(image)\n",
    "            dummy,predicted=torch.max(output.data,1)\n",
    "            correct_predicted+=(predicted==label).sum().item()\n",
    "        train_loss.append(training_loss/len(train_load.dataset))\n",
    "        training_accu=correct_predicted/len(train_load.dataset)\n",
    "        training_accuracy.append(training_accu)\n",
    "\n",
    "\n",
    "        model.eval()\n",
    "        validate_loss=0\n",
    "        val_correct_predicted=0\n",
    "        for image,label in val_load:\n",
    "            image,label=image.to(device),label.to(device)\n",
    "            output=model(image)\n",
    "            loss=loss_func(output,label)\n",
    "            gradient_descent.zero_grad()\n",
    "            loss.backward()\n",
    "            gradient_descent.step()\n",
    "            validate_loss+=loss.item()*len(image)\n",
    "            dummy,predicted=torch.max(output.data,1)\n",
    "            val_correct_predicted+=(predicted==label).sum().item()\n",
    "        validation_loss.append(validate_loss/len(val_load.dataset))\n",
    "        validation_accu=val_correct_predicted/len(val_load.dataset)\n",
    "        validation_accuracy.append(validation_accu)\n",
    "\n",
    "\n",
    "        model.eval()\n",
    "        test_correct_predicted=0\n",
    "        with torch.no_grad():\n",
    "            for image,label in test_load:\n",
    "                image,label=image.to(device),label.to(device)\n",
    "                output=model(image)\n",
    "                dummy,predicted=torch.max(output.data,1)\n",
    "                test_correct_predicted+=(predicted==label).sum().item()\n",
    "        testing_accu_base_model=test_correct_predicted/len(test_load.dataset) \n",
    "        testing_accuracy.append(testing_accu_base_model)\n",
    "        print(f'Epoch: {i+1} --------- Train Loss: {training_loss/len(train_load.dataset):.4f} --------- Train Accuracy: {training_accu:.4f} --------- Validation Loss: {validate_loss/len(val_load.dataset):.4f} --------- Validation Accuracy: {validation_accu:.4f}------------ Testing Accuracy: {testing_accu_base_model:.4f}')\n",
    "\n",
    "    return model,train_loss,training_accuracy,validation_loss,validation_accuracy,testing_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(test_loader, model):\n",
    "    test_correct_predicted=0\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "        model=model.to(device)\n",
    "        for image,label in test_loader:\n",
    "            image,label=image.to(device),label.to(device)\n",
    "            output=model(image)\n",
    "            dummy,predicted=torch.max(output.data,1)\n",
    "            test_correct_predicted+=(predicted==label).sum().item()\n",
    "    testing_accu=test_correct_predicted/len(test_loader.dataset)         \n",
    "    testing_accu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision.transforms as tt\n",
    "train_tfms = tt.Compose([\n",
    "                         tt.Grayscale(num_output_channels=3), # Pictures black and white\n",
    "                         tt.Resize([128, 128]),\n",
    "                         # Settings for expanding the dataset\n",
    "                         tt.RandomHorizontalFlip(),           # Random 90 degree rotations\n",
    "                         tt.RandomRotation(30),               # Random 30 degree rotations\n",
    "                         tt.ToTensor(),                      # Cast to tensor\n",
    "                         ])                      \n",
    "\n",
    "test_tfms = tt.Compose([\n",
    "                        tt.Grayscale(num_output_channels=3),\n",
    "                        tt.Resize([128, 128]),\n",
    "                        tt.ToTensor(),\n",
    "                        ])\n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import random_split\n",
    "\n",
    "dataset = ImageFolder(\"leapGestRecog\",transform=transforms.ToTensor()) # Replace with your dataset\n",
    "\n",
    "train_size = int(0.7 * len(dataset))\n",
    "val_size = int(0.1 * len(dataset))\n",
    "test_size = len(dataset) - train_size - val_size\n",
    "\n",
    "train_set, val_set, test_set = random_split(dataset,[train_size, val_size, test_size])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader=torch.utils.data.DataLoader(train_set,batch_size=256)\n",
    "test_loader=torch.utils.data.DataLoader(test_set,batch_size=256)\n",
    "val_loader=torch.utils.data.DataLoader(val_set,batch_size=256)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mCanceled future for execute_request message before replies were done"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the the current cell or a previous cell. Please review the code in the cell(s) to identify a possible cause of the failure. Click <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "model1=ResNet18(10)\n",
    "loss_function=nn.CrossEntropyLoss()\n",
    "optimizer=torch.optim.Adam(model1.parameters(),lr=1e-4)\n",
    "returns = train_model(epochs=10,model=model1,train_load=train_loader,val_load=val_loader,test_load=test_loader,loss_func=loss_function,gradient_descent=optimizer)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
