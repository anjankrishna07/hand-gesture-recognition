{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "import torch.utils.data as data\n",
    "from torchvision.datasets import ImageFolder\n",
    "from torch.utils.data import random_split\n",
    "from torch.utils.data import DataLoader, ConcatDataset\n",
    "import torch\n",
    "from torchvision import datasets\n",
    "from torchvision.transforms import transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class VGG16(nn.Module):\n",
    "    def __init__(self, num_classes=10):\n",
    "        super(VGG16, self).__init__()\n",
    "        self.features = nn.Sequential(\n",
    "            nn.Conv2d(3, 64, kernel_size=3, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(64, 64, kernel_size=3, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "            nn.Conv2d(64, 128, kernel_size=3, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(128, 128, kernel_size=3, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "            nn.Conv2d(128, 256, kernel_size=3, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(256, 256, kernel_size=3, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(256, 256, kernel_size=3, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "            nn.Conv2d(256, 512, kernel_size=3, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(512, 512, kernel_size=3, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(512, 512, kernel_size=3, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "            nn.Conv2d(512, 512, kernel_size=3, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(512, 512, kernel_size=3, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(512, 512, kernel_size=3, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "        )\n",
    "        self.avgpool = nn.AdaptiveAvgPool2d((7, 7))\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(512 * 7 * 7, 4096),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout(),\n",
    "            nn.Linear(4096, 4096),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout(),\n",
    "            nn.Linear(4096, num_classes),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.features(x)\n",
    "        x = self.avgpool(x)\n",
    "        x = torch.flatten(x, 1)\n",
    "        x = self.classifier(x)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_transforms = transforms.Compose([\n",
    "    transforms.RandomResizedCrop(size=224, scale=(0.8, 1.0)),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.ToTensor()\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset1 = ImageFolder(\"leapGestRecog\",transform=train_transforms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "transforms2=transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor()\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset2 = ImageFolder(\"leapGestRecog\",transform=transforms2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_file=data.ConcatDataset([dataset1, dataset2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "train=int(0.75 * len(data_file))\n",
    "test=int(0.15 * len(data_file))\n",
    "val=int(0.1 * len(data_file))\n",
    "training_set,testing_set,validation_set=torch.utils.data.random_split(data_file, [train,test,val])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader=torch.utils.data.DataLoader(training_set,batch_size=256)\n",
    "test_loader=torch.utils.data.DataLoader(testing_set,batch_size=256)\n",
    "val_loader=torch.utils.data.DataLoader(validation_set,batch_size=256)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(epochs,model,train_load,val_load,loss_func,gradient_descent):\n",
    "    train_loss=[]\n",
    "    training_accuracy=[]\n",
    "    validation_loss=[]\n",
    "    validation_accuracy=[]\n",
    "    testing_accuracy=[]\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model=model.to(device)\n",
    "    for i in range(epochs):\n",
    "        training_loss=0\n",
    "        correct_predicted=0\n",
    "        model.train()\n",
    "        for image,label in train_load:\n",
    "            image,label=image.to(device),label.to(device)\n",
    "            output=model(image)\n",
    "            loss=loss_func(output,label)\n",
    "            gradient_descent.zero_grad()\n",
    "            loss.backward()\n",
    "            gradient_descent.step()\n",
    "            training_loss+=loss.item()*len(image)\n",
    "            dummy,predicted=torch.max(output.data,1)\n",
    "            correct_predicted+=(predicted==label).sum().item()\n",
    "        train_loss.append(training_loss/len(train_load.dataset))\n",
    "        training_accu=correct_predicted/len(train_load.dataset)\n",
    "        training_accuracy.append(training_accu)\n",
    "\n",
    "\n",
    "        model.eval()\n",
    "        validate_loss=0\n",
    "        val_correct_predicted=0\n",
    "        for image,label in val_load:\n",
    "            image,label=image.to(device),label.to(device)\n",
    "            output=model(image)\n",
    "            loss=loss_func(output,label)\n",
    "            gradient_descent.zero_grad()\n",
    "            loss.backward()\n",
    "            gradient_descent.step()\n",
    "            validate_loss+=loss.item()*len(image)\n",
    "            dummy,predicted=torch.max(output.data,1)\n",
    "            val_correct_predicted+=(predicted==label).sum().item()\n",
    "        validation_loss.append(validate_loss/len(val_load.dataset))\n",
    "        validation_accu=val_correct_predicted/len(val_load.dataset)\n",
    "        validation_accuracy.append(validation_accu)\n",
    "        print(f'Epoch: {i+1} --------- Train Loss: {training_loss/len(train_load.dataset):.4f} --------- Train Accuracy: {training_accu:.4f} --------- Validation Loss: {validate_loss/len(val_load.dataset):.4f} --------- Validation Accuracy: {validation_accu:.4f}')\n",
    "\n",
    "    return model,train_loss,training_accuracy,validation_loss,validation_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(test_loader, model):\n",
    "    test_correct_predicted=0\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "        model=model.to(device)\n",
    "        for image,label in test_loader:\n",
    "            image,label=image.to(device),label.to(device)\n",
    "            output=model(image)\n",
    "            dummy,predicted=torch.max(output.data,1)\n",
    "            test_correct_predicted+=(predicted==label).sum().item()\n",
    "    testing_accu=test_correct_predicted/len(test_loader.dataset)         \n",
    "    return testing_accu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "model2=VGG16(10)\n",
    "loss_function=nn.CrossEntropyLoss()\n",
    "optimizer=torch.optim.Adam(model2.parameters(),lr=1e-4)\n",
    "returns = train_model(epochs=10,model=model2,train_load=train_loader,val_load=val_loader,loss_func=loss_function,gradient_descent=optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
